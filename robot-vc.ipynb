{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hoang\\\\OneDrive\\\\Projects\\\\Personal\\\\Research\\\\SpeechResearch\\\\Voice Conversion'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure TRIAAN-VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TRIAAN = os.path.join(os.getcwd(), 'models', 'TRIAAN-VC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested with Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters List\n",
    "- `--config` : direct of configuration file \n",
    "- `--device` : device to run the conversion on (default: `cuda:0`)\n",
    "- `--sample_path`: path to the sample data\n",
    "- `--src_name`: name of the source data \n",
    "- `--trg_name`: name of the target data\n",
    "- `--checkpoints`: path to the checkpoints directory\n",
    "- `--model_name`: name of the model, injecting with the custom pre-trained path\n",
    "- `--seed`: seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\triaan-vc\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\cpc\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\vocoder\n"
     ]
    }
   ],
   "source": [
    "# configure path to the pretrained model\n",
    "PRETRAINED_TRIAAN = os.path.join(os.getcwd(), 'pre-trained','triaan-vc')\n",
    "### others pretrained models: CPC, Vocoder -------------------\n",
    "PRETRAINED_CPC = os.path.join(os.getcwd(), 'pre-trained','cpc')\n",
    "PRETRAINED_Vocoder = os.path.join(os.getcwd(), 'pre-trained','vocoder')\n",
    "\n",
    "print(PRETRAINED_TRIAAN)\n",
    "print(PRETRAINED_CPC)\n",
    "print(PRETRAINED_Vocoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folder configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\models\\TRIAAN-VC\\convert.py\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\models\\TRIAAN-VC\\config\\base.yaml\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\triaan-vc\\model-cpc-split.pth\n"
     ]
    }
   ],
   "source": [
    "# path to model configuration\n",
    "convert_file = os.path.join(ORIGINAL_TRIAAN, 'convert.py')\n",
    "original_config = os.path.join(ORIGINAL_TRIAAN, 'config', 'base.yaml')\n",
    "triaan_model = os.path.join(PRETRAINED_TRIAAN, 'model-cpc-split.pth') \n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "data_source = './data'\n",
    "checkpoint_dir = './checkpoints'\n",
    "\n",
    "print(convert_file)\n",
    "print(original_config)\n",
    "print(triaan_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File source**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source and target audio files\n",
    "source_name = 'MONTREAL_6_happiness_m.wav'\n",
    "target_name = 'ken8hapvoc.wav'\n",
    "\n",
    "# source_name = 'film_female_1.mp3'\n",
    "# target_name = 'film_male_1.mp3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the original model to the pre-trained model\n",
    "#os.system(f'python {convert_file} --device {device} --config {original_config} --sample_path {data_source} --src_name {source_name} --trg_name {target_name} --checkpoint {checkpoint_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python  --device cpu --sample_path ./data --src_name MONTREAL_6_happiness_m.wav --trg_name ken8hapvoc.wav  --checkpoint ./checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Original model and fine-tune with custom data for specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/winddori2002/TriAAN-VC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In preporcessing phase (`audio.py`)file, normalise the pitch and loudness of the audio files \n",
    "- Recreate the preprocess configuration file (with customise data - robotic data)\n",
    "- Dataset that we need to use: `WILLOW, BEST (Possible EMOGIB)`\n",
    "- Train the model with the new configuration\n",
    "- Save the new model\n",
    "- Evaluate the model ~ WER, CER, SV Average\n",
    "  \n",
    "\n",
    "**Original dataset:** VCTK - 110 speakers with 400 utterances per speaker.\n",
    "\n",
    "***Custom dataset:*** Robotic data\n",
    "\n",
    "**Expected  Output**: The model can be use to convert the human speaking voice into robotic voice and it also encapsulating all the pause, and different in timbre. Source input will be human voice, target input will be robotic voice and the output is the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the preprocess.py file in the TRIAAN-VC model, with specify parameters\n",
    "\n",
    "def get_triaan_preprocess():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the train or test in the TRIAAN-VC model, with specify parameters:\n",
    "# action # train / test\n",
    "# --config # path to config file\n",
    "# --num_worker # number of workers\n",
    "# --seed # seed number\n",
    "# --device # cuda device - cpu or device\n",
    "# --logging # logging option\n",
    "# --resume # resume option\n",
    "# --checkpoint # results save path\n",
    "# --model_name # best model name\n",
    "# --n_uttr # number of target utterances (default 1)\n",
    "def get_triaan_execute():\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the convert.py file in the TRIAAN-VC model, with specify parameters\n",
    "\n",
    "def get_triaan_convert():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voiceconversion-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
