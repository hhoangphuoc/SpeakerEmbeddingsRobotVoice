{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os.path import join as opj "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure TRIAAN-VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "ORIGINAL_MODEL_PATH = opj(os.getcwd(), 'models', 'triaanvc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested with Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters List\n",
    "- `--config` : direct of configuration file \n",
    "- `--device` : device to run the conversion on (default: `cuda:0`)\n",
    "- `--sample_path`: path to the sample data\n",
    "- `--src_name`: name of the source data \n",
    "- `--trg_name`: name of the target data\n",
    "- `--checkpoints`: path to the checkpoints directory\n",
    "- `--model_name`: name of the model, injecting with the custom pre-trained path\n",
    "- `--seed`: seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\triaan-vc\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\cpc\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\vocoder\n"
     ]
    }
   ],
   "source": [
    "# configure path to the pretrained model\n",
    "PRETRAINED_TRIAAN = os.path.join(os.getcwd(), 'pre-trained','triaan-vc')\n",
    "### others pretrained models: CPC, Vocoder -------------------\n",
    "PRETRAINED_CPC = os.path.join(os.getcwd(), 'pre-trained','cpc')\n",
    "PRETRAINED_Vocoder = os.path.join(os.getcwd(), 'pre-trained','vocoder')\n",
    "\n",
    "print(PRETRAINED_TRIAAN)\n",
    "print(PRETRAINED_CPC)\n",
    "print(PRETRAINED_Vocoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folder configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\models\\TRIAAN-VC\\convert.py\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\models\\TRIAAN-VC\\config\\base.yaml\n",
      "c:\\Users\\hoang\\OneDrive\\Projects\\Personal\\Research\\SpeechResearch\\Voice Conversion\\pre-trained\\triaan-vc\\model-cpc-split.pth\n"
     ]
    }
   ],
   "source": [
    "# path to model configuration\n",
    "convert_file = os.path.join(ORIGINAL_TRIAAN, 'convert.py')\n",
    "original_config = os.path.join(ORIGINAL_TRIAAN, 'config', 'base.yaml')\n",
    "triaan_model = os.path.join(PRETRAINED_TRIAAN, 'model-cpc-split.pth') \n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "data_source = './data'\n",
    "checkpoint_dir = './checkpoints'\n",
    "\n",
    "print(convert_file)\n",
    "print(original_config)\n",
    "print(triaan_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File source**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source and target audio files\n",
    "source_name = 'MONTREAL_6_happiness_m.wav'\n",
    "target_name = 'ken8hapvoc.wav'\n",
    "\n",
    "# source_name = 'film_female_1.mp3'\n",
    "# target_name = 'film_male_1.mp3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the original model to the pre-trained model\n",
    "#os.system(f'python {convert_file} --device {device} --config {original_config} --sample_path {data_source} --src_name {source_name} --trg_name {target_name} --checkpoint {checkpoint_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python  --device cpu --sample_path ./data --src_name MONTREAL_6_happiness_m.wav --trg_name ken8hapvoc.wav  --checkpoint ./checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Original model and fine-tune with custom data for specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/winddori2002/TriAAN-VC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In preporcessing phase (`audio.py`)file, normalise the pitch and loudness of the audio files \n",
    "- Recreate the preprocess configuration file (with customise data - robotic data)\n",
    "- Dataset that we need to use: `WILLOW, BEST (Possible EMOGIB)`\n",
    "- Train the model with the new configuration\n",
    "- Save the new model\n",
    "- Evaluate the model ~ WER, CER, SV Average\n",
    "  \n",
    "\n",
    "**Original dataset:** VCTK - 110 speakers with 400 utterances per speaker.\n",
    "\n",
    "***Custom dataset:*** Robotic data\n",
    "\n",
    "**Expected  Output**: The model can be use to convert the human speaking voice into robotic voice and it also encapsulating all the pause, and different in timbre. Source input will be human voice, target input will be robotic voice and the output is the conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO: Rewrite all the functions to match with custom data. We only keep the model architecture, but the data processing, training, and evaluation will be re-written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIX PATH\n",
    "input_path = './data/Phuoc/input'\n",
    "output_path = './data/Phuoc/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyyaml\n",
    "from modified_audio_process import * #import all the functions changes for preprocessing audio\n",
    "from models.triaanvc.src.utils import Config\n",
    "\n",
    "#import preprocess, convert, train and test functions\n",
    "# from models.triaanvc.preprocess_cpc import main as model_preprocess_cpc\n",
    "# from models.triaanvc.preprocess import main as model_preprocess\n",
    "# from models.triaanvc.convert import main as model_convert\n",
    "# from models.triaanvc.train import main as model_train\n",
    "# from models.triaanvc.test import main as model_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modified Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cfg = Config('./custom-config/preprocess.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triaan_preprocess():\n",
    "    # model_preprocess\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the train or test in the TRIAAN-VC model, with specify parameters:\n",
    "# action # train / test\n",
    "# --config # path to config file\n",
    "# --num_worker # number of workers\n",
    "# --seed # seed number\n",
    "# --device # cuda device - cpu or device\n",
    "# --logging # logging option\n",
    "# --resume # resume option\n",
    "# --checkpoint # results save path\n",
    "# --model_name # best model name\n",
    "# --n_uttr # number of target utterances (default 1)\n",
    "def get_triaan_execute():\n",
    "    # using model_train or model_test\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the convert.py file in the TRIAAN-VC model, with specify parameters\n",
    "def get_triaan_convert():\n",
    "    # using model_convert\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voiceconversion-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
